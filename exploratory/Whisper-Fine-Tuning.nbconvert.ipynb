{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08bd6b56",
   "metadata": {},
   "source": [
    "# Whisper Fine Tuning\n",
    "\n",
    "In this notebook, we will fine tune an openai whisper model on Irish accent data.\n",
    "\n",
    "Heavily based on: https://huggingface.co/blog/fine-tune-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b8653b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:09.607729Z",
     "iopub.status.busy": "2023-04-27T15:35:09.607467Z",
     "iopub.status.idle": "2023-04-27T15:35:10.751462Z",
     "shell.execute_reply": "2023-04-27T15:35:10.750489Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperProcessor\n",
    "from datasets import (\n",
    "    Audio,\n",
    "    load_dataset,\n",
    "    load_dataset_builder,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    "    DatasetDict,\n",
    ")\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987291de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:10.755774Z",
     "iopub.status.busy": "2023-04-27T15:35:10.754884Z",
     "iopub.status.idle": "2023-04-27T15:35:10.774572Z",
     "shell.execute_reply": "2023-04-27T15:35:10.773791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca99a0ed96b4f9ab7846c4da683c364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f43359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:10.786772Z",
     "iopub.status.busy": "2023-04-27T15:35:10.786136Z",
     "iopub.status.idle": "2023-04-27T15:35:10.791559Z",
     "shell.execute_reply": "2023-04-27T15:35:10.790693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was already processed!\n"
     ]
    }
   ],
   "source": [
    "# This is approx 80Gb, download at your peril!\n",
    "\n",
    "if not os.path.exists('irish-accent-common-voice-test'):\n",
    "    common_voice = load_dataset(\n",
    "        \"mozilla-foundation/common_voice_11_0\", \"en\", use_auth_token=True, cache_dir='/mnt/vol_c/huggingface/'\n",
    "    )\n",
    "\n",
    "    print(common_voice)\n",
    "else:\n",
    "    print('Data was already processed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3df8d",
   "metadata": {},
   "source": [
    "## Filter to Irish Accent Data\n",
    "\n",
    "Here we are going to filter the large common voice dataset to just those rows that have an Irish accent speaker. The overall aim being to produce a model that has a better performance on Irish accents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e04dc7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:10.795409Z",
     "iopub.status.busy": "2023-04-27T15:35:10.794581Z",
     "iopub.status.idle": "2023-04-27T15:35:10.801752Z",
     "shell.execute_reply": "2023-04-27T15:35:10.800919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was already processed!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('irish-accent-common-voice-test'):\n",
    "    filtered_train = common_voice['train'].filter(\n",
    "        lambda x: 'irish' in x['accent'].lower() or 'ireland' in x['accent'].lower()\n",
    "    )\n",
    "    filtered_val = common_voice['validation'].filter(\n",
    "        lambda x: 'irish' in x['accent'].lower() or 'ireland' in x['accent'].lower()\n",
    "    )\n",
    "    filtered_test = common_voice['test'].filter(\n",
    "        lambda x: 'irish' in x['accent'].lower() or 'ireland' in x['accent'].lower()\n",
    "    )\n",
    "    print(len(filtered_train), len(filtered_val), len(filtered_test))\n",
    "else:\n",
    "    print('Data was already processed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361187c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:10.805402Z",
     "iopub.status.busy": "2023-04-27T15:35:10.804640Z",
     "iopub.status.idle": "2023-04-27T15:35:10.809077Z",
     "shell.execute_reply": "2023-04-27T15:35:10.808236Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('irish-accent-common-voice-test'):\n",
    "\n",
    "    # Merge dataseto rebalance train vs test\n",
    "    merged_dataset = concatenate_datasets([filtered_train, filtered_test, filtered_val])\n",
    "    merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb77ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:10.812582Z",
     "iopub.status.busy": "2023-04-27T15:35:10.811840Z",
     "iopub.status.idle": "2023-04-27T15:35:10.816087Z",
     "shell.execute_reply": "2023-04-27T15:35:10.815263Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('irish-accent-common-voice-test'):\n",
    "\n",
    "    split_dataset = merged_dataset.train_test_split(0.2)\n",
    "    split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf22928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:10.819661Z",
     "iopub.status.busy": "2023-04-27T15:35:10.818912Z",
     "iopub.status.idle": "2023-04-27T15:35:10.834180Z",
     "shell.execute_reply": "2023-04-27T15:35:10.833381Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('irish-accent-common-voice-test'):\n",
    "    split_dataset['train'].save_to_disk('irish-accent-common-voice-train')\n",
    "    split_dataset['test'].save_to_disk('irish-accent-common-voice-test')\n",
    "else:\n",
    "    split_dataset = DatasetDict()\n",
    "    split_dataset['train'] = load_from_disk('irish-accent-common-voice-train')\n",
    "    split_dataset['test'] = load_from_disk('irish-accent-common-voice-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f8543f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:10.837558Z",
     "iopub.status.busy": "2023-04-27T15:35:10.837035Z",
     "iopub.status.idle": "2023-04-27T15:35:10.849865Z",
     "shell.execute_reply": "2023-04-27T15:35:10.849019Z"
    }
   },
   "outputs": [],
   "source": [
    "split_dataset = split_dataset.remove_columns(\n",
    "    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",
    ")\n",
    "split_dataset = split_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be314058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:10.853368Z",
     "iopub.status.busy": "2023-04-27T15:35:10.852602Z",
     "iopub.status.idle": "2023-04-27T15:35:11.619746Z",
     "shell.execute_reply": "2023-04-27T15:35:11.618323Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0aa0e43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:11.624312Z",
     "iopub.status.busy": "2023-04-27T15:35:11.623706Z",
     "iopub.status.idle": "2023-04-27T15:35:11.630070Z",
     "shell.execute_reply": "2023-04-27T15:35:11.629179Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7f7432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:11.633618Z",
     "iopub.status.busy": "2023-04-27T15:35:11.632964Z",
     "iopub.status.idle": "2023-04-27T15:35:15.055013Z",
     "shell.execute_reply": "2023-04-27T15:35:15.054060Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/irish-accent-common-voice-train/cache-566430680320d43a_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/irish-accent-common-voice-test/cache-49b2ec5d50089605_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "split_dataset = split_dataset.map(prepare_dataset, remove_columns=split_dataset.column_names[\"train\"], num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2506bbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:15.059298Z",
     "iopub.status.busy": "2023-04-27T15:35:15.058512Z",
     "iopub.status.idle": "2023-04-27T15:35:16.231355Z",
     "shell.execute_reply": "2023-04-27T15:35:16.228975Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87b9d0c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:16.237748Z",
     "iopub.status.busy": "2023-04-27T15:35:16.237250Z",
     "iopub.status.idle": "2023-04-27T15:35:16.243454Z",
     "shell.execute_reply": "2023-04-27T15:35:16.242496Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce317944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:16.247338Z",
     "iopub.status.busy": "2023-04-27T15:35:16.246870Z",
     "iopub.status.idle": "2023-04-27T15:35:17.924899Z",
     "shell.execute_reply": "2023-04-27T15:35:17.923734Z"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1d8746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:17.929653Z",
     "iopub.status.busy": "2023-04-27T15:35:17.929249Z",
     "iopub.status.idle": "2023-04-27T15:35:17.935295Z",
     "shell.execute_reply": "2023-04-27T15:35:17.934277Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d9945e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:17.939344Z",
     "iopub.status.busy": "2023-04-27T15:35:17.938795Z",
     "iopub.status.idle": "2023-04-27T15:35:23.505810Z",
     "shell.execute_reply": "2023-04-27T15:35:23.504373Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "477cdbfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:23.510711Z",
     "iopub.status.busy": "2023-04-27T15:35:23.510281Z",
     "iopub.status.idle": "2023-04-27T15:35:24.186901Z",
     "shell.execute_reply": "2023-04-27T15:35:24.185775Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/mnt/vol_c/whisper-small-en-irish-accent-3\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=5e-6,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=400,\n",
    "    eval_steps=400,\n",
    "    logging_steps=25,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcd52066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:24.191953Z",
     "iopub.status.busy": "2023-04-27T15:35:24.191489Z",
     "iopub.status.idle": "2023-04-27T15:35:27.575108Z",
     "shell.execute_reply": "2023-04-27T15:35:27.573758Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "236d19c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:35:27.579825Z",
     "iopub.status.busy": "2023-04-27T15:35:27.579368Z",
     "iopub.status.idle": "2023-04-27T22:11:12.042265Z",
     "shell.execute_reply": "2023-04-27T22:11:12.041000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2414' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2414/4000 4:25:29 < 2:54:34, 0.15 it/s, Epoch 3.64/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.206165</td>\n",
       "      <td>11.315683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.183969</td>\n",
       "      <td>10.663917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>10.840667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.191588</td>\n",
       "      <td>10.792797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.190812</td>\n",
       "      <td>10.730198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.207609</td>\n",
       "      <td>11.061605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/transformers/trainer.py:1899\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1896\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1899\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1900\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1901\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    556\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    559\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/datasets/arrow_dataset.py:2709\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/datasets/arrow_dataset.py:2694\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2692\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2693\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2694\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/datasets/formatting/formatting.py:642\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     pa_table_to_format \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mdrop(col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn_names \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m format_columns)\n\u001b[0;32m--> 642\u001b[0m     formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table_to_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_all_columns:\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_output, MutableMapping):\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/datasets/formatting/formatting.py:406\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/datasets/formatting/formatting.py:441\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m/usr/local/share/miniconda/lib/python3.9/site-packages/datasets/formatting/formatting.py:144\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d9de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  unzip\n",
      "The following NEW packages will be installed:\n",
      "  unzip zip\n",
      "0 upgraded, 2 newly installed, 0 to remove and 233 not upgraded.\n",
      "Need to get 335 kB of archives.\n",
      "After this operation, 1,231 kB of additional disk space will be used.\n",
      "Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "Get:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 zip amd64 3.0-11build1 [167 kB]\n",
      "Fetched 335 kB in 0s (1,600 kB/s)\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 88617 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-25ubuntu1.1_amd64.deb ...\n",
      "Unpacking unzip (6.0-25ubuntu1.1) ...\n",
      "Selecting previously unselected package zip.\n",
      "Preparing to unpack .../zip_3.0-11build1_amd64.deb ...\n",
      "Unpacking zip (3.0-11build1) ...\n",
      "Setting up unzip (6.0-25ubuntu1.1) ...\n",
      "Setting up zip (3.0-11build1) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Processing triggers for mime-support (3.64ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -y zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bba4d6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/ (stored 0%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/training_args.bin (deflated 48%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/generation_config.json (deflated 71%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/trainer_state.json (deflated 80%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/scheduler.pt (deflated 48%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/pytorch_model.bin (deflated 7%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/preprocessor_config.json (deflated 42%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/config.json (deflated 63%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/optimizer.pt (deflated 7%)\n",
      "  adding: mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/rng_state.pth (deflated 28%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /mnt/vol_c/whisper-small-en-irish-accent-3-best.zip /mnt/vol_c/whisper-small-en-irish-accent-3/checkpoint-800/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f802e5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1aa8e681bbf34a2abfb0b7fc946c60e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30e2881516bd47bfb06e25efb5226d91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8054984326fd42659ac1a695d5334904",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_efd6f4a952e94e33a331270aac841ba8",
       "tabbable": null,
       "tooltip": null,
       "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
      }
     },
     "3a9e50dc381b4beeae3dc29ba1d7d1e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "TextStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42ce7736eb494aed9d72c34f5687e710": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "PasswordModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "PasswordModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "PasswordView",
       "continuous_update": true,
       "description": "Token:",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_9de241d2076a46de9223e1ff3f3a140d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_3a9e50dc381b4beeae3dc29ba1d7d1e4",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "4319a6441bcf400a9cc50b7189326749": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "CheckboxStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "CheckboxStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": ""
      }
     },
     "6266a188d5a642169d3bba03aae1b830": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "65c243eb9a0a42b5acabdbe6fc031baf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": "center",
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "flex",
       "flex": null,
       "flex_flow": "column",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "50%"
      }
     },
     "69ae342ed9bb4b11b7d968b05ed95e56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "CheckboxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "CheckboxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "CheckboxView",
       "description": "Add token as git credential?",
       "description_allow_html": false,
       "disabled": false,
       "indent": true,
       "layout": "IPY_MODEL_87c21c16318b4bf0b95fa114feee979f",
       "style": "IPY_MODEL_4319a6441bcf400a9cc50b7189326749",
       "tabbable": null,
       "tooltip": null,
       "value": true
      }
     },
     "8054984326fd42659ac1a695d5334904": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80eaefb4222b481e90562471a51e3474": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_89b80f026e1746dcb2b1e60e078b7cb9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8b932b13829240dc80dc83df3c85943a",
       "tabbable": null,
       "tooltip": null,
       "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
      }
     },
     "87c21c16318b4bf0b95fa114feee979f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89b80f026e1746dcb2b1e60e078b7cb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b932b13829240dc80dc83df3c85943a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9de241d2076a46de9223e1ff3f3a140d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb6f0d4d35a24894b1abf5259c0dc794": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "Login",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_1aa8e681bbf34a2abfb0b7fc946c60e5",
       "style": "IPY_MODEL_6266a188d5a642169d3bba03aae1b830",
       "tabbable": null,
       "tooltip": null
      }
     },
     "dd45a534d56349cbae97f20111d478e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_80eaefb4222b481e90562471a51e3474",
        "IPY_MODEL_42ce7736eb494aed9d72c34f5687e710",
        "IPY_MODEL_69ae342ed9bb4b11b7d968b05ed95e56",
        "IPY_MODEL_bb6f0d4d35a24894b1abf5259c0dc794",
        "IPY_MODEL_30e2881516bd47bfb06e25efb5226d91"
       ],
       "layout": "IPY_MODEL_65c243eb9a0a42b5acabdbe6fc031baf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "efd6f4a952e94e33a331270aac841ba8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
